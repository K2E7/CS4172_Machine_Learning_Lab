{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from datetime import datetime\n",
        "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, Activation, Dropout, BatchNormalization\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import pandas as pad\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "import keras"
      ],
      "metadata": {
        "id": "ouQLIS1P6XI7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.datasets import mnist\n",
        "\n",
        "# Download the MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ],
      "metadata": {
        "id": "3Yb8WOv4JO7P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random"
      ],
      "metadata": {
        "id": "8uCmjRJiKMQE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def RBF(x, c, s):\n",
        "    return np.exp(-np.sum((x-c)**2, axis=1)/(2*s**2))\n"
      ],
      "metadata": {
        "id": "uoObm1DkKPA8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Randomly sample the training set without replacement\n",
        "num_samples = int(len(x_train) / 10)\n",
        "x_train_reduced = x_train[random.sample(range(len(x_train)), num_samples)]\n",
        "y_train_reduced = y_train[random.sample(range(len(y_train)), num_samples)]"
      ],
      "metadata": {
        "id": "wo0NRhuDKRgj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train data shape: \", x_train.shape, y_train.shape)\n",
        "print(\"Test data shape: \", x_test.shape, y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1mrHxs-DOUoL",
        "outputId": "4fde4cc4-7a07-4697-c9b7-3af12476ed2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data shape:  (60000, 28, 28) (60000,)\n",
            "Test data shape:  (10000, 28, 28) (10000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train Data Reduced shape: \", x_train_reduced.shape, y_train_reduced.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tig0R6ovOXcz",
        "outputId": "7bd439e8-c445-460b-a3c1-c6faaed74e19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Data Reduced shape:  (6000, 28, 28) (6000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def transform(image):\n",
        "    image = np.pad(image, (2, 2))\n",
        "    c = np.mean(image)\n",
        "    s = np.std(image)\n",
        "    return RBF(image, c, s).flatten()"
      ],
      "metadata": {
        "id": "hTnmE_43Ok4X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_tf = []\n",
        "for image in x_train:\n",
        "    x_train_tf.append(transform(image))\n",
        "x_train_tf = np.array(x_train_tf)\n",
        "print(\"Shape of x_train after transforming: \", x_train_tf.shape)\n",
        "x_test_tf = []\n",
        "for image in x_test:\n",
        "    x_test_tf.append(transform(image))\n",
        "x_test_tf = np.array(x_test_tf)\n",
        "print(\"Shape of x_test after transforming: \", x_test_tf.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KIKLrm57OsnK",
        "outputId": "baffe894-8e63-46f9-ec6a-81b2961aac21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of x_train after transforming:  (60000, 32)\n",
            "Shape of x_test after transforming:  (10000, 32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def split_train_test_val(x_train_tf, train_size=0.8, test_size=0.1, val_size=0.1):\n",
        "  \"\"\"Splits a NumPy array into training, testing, and validation datasets.\n",
        "\n",
        "  Args:\n",
        "    x_train_tf: A NumPy array to split.\n",
        "    train_size: The proportion of the data to use for training.\n",
        "    test_size: The proportion of the data to use for testing.\n",
        "    val_size: The proportion of the data to use for validation.\n",
        "\n",
        "  Returns:\n",
        "    A tuple of three NumPy arrays: training data, testing data, and validation\n",
        "    data.\n",
        "  \"\"\"\n",
        "\n",
        "  # Calculate the number of samples in each dataset.\n",
        "  n_train = int(train_size * len(x_train_tf))\n",
        "  n_test = int(test_size * len(x_train_tf))\n",
        "  n_val = int(val_size * len(x_train_tf))\n",
        "\n",
        "  # Shuffle the data.\n",
        "  np.random.shuffle(x_train_tf)\n",
        "\n",
        "  # Split the data into training, testing, and validation datasets.\n",
        "  train = x_train_tf[:n_train]\n",
        "  test = x_train_tf[n_train:n_train + n_test]\n",
        "  val = x_train_tf[n_train + n_test:]\n",
        "\n",
        "  return train, test, val"
      ],
      "metadata": {
        "id": "izAbueVeOxEA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "encoder = OneHotEncoder()\n",
        "\n",
        "y_train = encoder.fit_transform(y_train.reshape(-1, 1)).toarray()\n",
        "y_test = encoder.transform(y_test.reshape(-1, 1)).toarray()\n",
        "\n",
        "print(\"Shape of y_train after OHE: \", y_train.shape)\n",
        "print(\"Shape of y_test after OHE: \", y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TiD7t464QOpu",
        "outputId": "519a275e-3885-4f8f-e7a0-d6289903d5c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of y_train after OHE:  (60000, 10)\n",
            "Shape of y_test after OHE:  (10000, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tf.__version__)"
      ],
      "metadata": {
        "id": "L8qpgUrRS4yu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15221558-b856-4959-9260-b8880459806f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.14.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.1 Activation function : Sigmoid | Hidden Neurons : [16]\n"
      ],
      "metadata": {
        "id": "1FFB0OprSf7o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "input_layer = Input(shape=(32, ))\n",
        "dense_layer = Dense(16, activation='sigmoid')(input_layer)\n",
        "output_layer = Dense(10, activation='softmax',\n",
        "                     kernel_initializer='glorot_normal')(dense_layer)\n",
        "\n",
        "model = Model(inputs=input_layer, outputs=output_layer)\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mn1iVLOwSyCs",
        "outputId": "38f060b3-f2bf-46ec-c674-e4953adcb38f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 32)]              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 16)                528       \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                170       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 698 (2.73 KB)\n",
            "Trainable params: 698 (2.73 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir model1_1\n",
        "model_path = \"model1_1/\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A1uESr5nTODv",
        "outputId": "d600739f-82de-443f-9b87-04a38ce12447"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘model1_1’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "adam = Adam(learning_rate=0.001)"
      ],
      "metadata": {
        "id": "lHFHAZKkTV_n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting the filepath for the ModelCheckpoint callback to save the files\n",
        "filepath = model_path+\"{epoch:02d}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(\n",
        "    filepath=filepath, monitor='val_loss',  verbose=1, save_best_only=True, mode='auto')\n",
        "\n",
        "# We will use the EarlyStopping callback to prevent the model from training after the optimal condition has been met\n",
        "earlystop = EarlyStopping(\n",
        "    monitor='val_loss', patience=7, verbose=1, mode='min')\n",
        "\n",
        "# Passing validation data into the custom Metrics callback that we have created\n",
        "validation_data = (x_test_tf, y_test)\n",
        "\n",
        "model.compile(optimizer=adam, loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "wd39VdPhTPTe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !rm -rf ./logs1_1/fit"
      ],
      "metadata": {
        "id": "UIlPY7ReVwTC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "log_dir = \"logs1_1/fit/\" + datetime.now().strftime(\"%Y%m%d - %H%M%S\")\n",
        "\n",
        "tf.keras.utils.plot_model(model, to_file=model_path +\n",
        "                          'model.png', show_shapes=True)\n",
        "\n",
        "tbCallBack = TensorBoard(log_dir=log_dir, write_graph=True,\n",
        "                         write_grads=True, write_images=True)\n",
        "\n",
        "allCs = [tbCallBack, earlystop, checkpoint]\n",
        "\n",
        "model.fit(x_train_tf, y_train, epochs=50,\n",
        "          validation_data=validation_data, batch_size=256, callbacks=allCs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BwemF-uJTc5W",
        "outputId": "f10b8829-4646-4df8-9c88-8127ef395079"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`write_grads` will be ignored in TensorFlow 2.0 for the `TensorBoard` Callback.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "234/235 [============================>.] - ETA: 0s - loss: 2.2956 - accuracy: 0.1716\n",
            "Epoch 1: val_loss improved from inf to 2.24427, saving model to model1_1/01.hdf5\n",
            "235/235 [==============================] - 4s 9ms/step - loss: 2.2955 - accuracy: 0.1718 - val_loss: 2.2443 - val_accuracy: 0.2247\n",
            "Epoch 2/50\n",
            "  9/235 [>.............................] - ETA: 1s - loss: 2.2447 - accuracy: 0.2088"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "232/235 [============================>.] - ETA: 0s - loss: 2.1966 - accuracy: 0.2517\n",
            "Epoch 2: val_loss improved from 2.24427 to 2.14137, saving model to model1_1/02.hdf5\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 2.1961 - accuracy: 0.2519 - val_loss: 2.1414 - val_accuracy: 0.2883\n",
            "Epoch 3/50\n",
            "213/235 [==========================>...] - ETA: 0s - loss: 2.0846 - accuracy: 0.3038\n",
            "Epoch 3: val_loss improved from 2.14137 to 2.02112, saving model to model1_1/03.hdf5\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.0798 - accuracy: 0.3067 - val_loss: 2.0211 - val_accuracy: 0.3339\n",
            "Epoch 4/50\n",
            "231/235 [============================>.] - ETA: 0s - loss: 1.9600 - accuracy: 0.3560\n",
            "Epoch 4: val_loss improved from 2.02112 to 1.90659, saving model to model1_1/04.hdf5\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 1.9596 - accuracy: 0.3559 - val_loss: 1.9066 - val_accuracy: 0.3504\n",
            "Epoch 5/50\n",
            "213/235 [==========================>...] - ETA: 0s - loss: 1.8537 - accuracy: 0.3756\n",
            "Epoch 5: val_loss improved from 1.90659 to 1.80790, saving model to model1_1/05.hdf5\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 1.8495 - accuracy: 0.3770 - val_loss: 1.8079 - val_accuracy: 0.3801\n",
            "Epoch 6/50\n",
            "214/235 [==========================>...] - ETA: 0s - loss: 1.7613 - accuracy: 0.3967\n",
            "Epoch 6: val_loss improved from 1.80790 to 1.72871, saving model to model1_1/06.hdf5\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 1.7573 - accuracy: 0.3968 - val_loss: 1.7287 - val_accuracy: 0.3971\n",
            "Epoch 7/50\n",
            "216/235 [==========================>...] - ETA: 0s - loss: 1.6858 - accuracy: 0.4116\n",
            "Epoch 7: val_loss improved from 1.72871 to 1.66789, saving model to model1_1/07.hdf5\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 1.6843 - accuracy: 0.4115 - val_loss: 1.6679 - val_accuracy: 0.4155\n",
            "Epoch 8/50\n",
            "230/235 [============================>.] - ETA: 0s - loss: 1.6291 - accuracy: 0.4239\n",
            "Epoch 8: val_loss improved from 1.66789 to 1.62096, saving model to model1_1/08.hdf5\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 1.6280 - accuracy: 0.4243 - val_loss: 1.6210 - val_accuracy: 0.4261\n",
            "Epoch 9/50\n",
            "212/235 [==========================>...] - ETA: 0s - loss: 1.5859 - accuracy: 0.4338\n",
            "Epoch 9: val_loss improved from 1.62096 to 1.58452, saving model to model1_1/09.hdf5\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 1.5848 - accuracy: 0.4349 - val_loss: 1.5845 - val_accuracy: 0.4307\n",
            "Epoch 10/50\n",
            "230/235 [============================>.] - ETA: 0s - loss: 1.5509 - accuracy: 0.4438\n",
            "Epoch 10: val_loss improved from 1.58452 to 1.55649, saving model to model1_1/10.hdf5\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 1.5513 - accuracy: 0.4434 - val_loss: 1.5565 - val_accuracy: 0.4339\n",
            "Epoch 11/50\n",
            "226/235 [===========================>..] - ETA: 0s - loss: 1.5256 - accuracy: 0.4484\n",
            "Epoch 11: val_loss improved from 1.55649 to 1.53462, saving model to model1_1/11.hdf5\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 1.5250 - accuracy: 0.4482 - val_loss: 1.5346 - val_accuracy: 0.4432\n",
            "Epoch 12/50\n",
            "218/235 [==========================>...] - ETA: 0s - loss: 1.5057 - accuracy: 0.4533\n",
            "Epoch 12: val_loss improved from 1.53462 to 1.51799, saving model to model1_1/12.hdf5\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 1.5044 - accuracy: 0.4541 - val_loss: 1.5180 - val_accuracy: 0.4384\n",
            "Epoch 13/50\n",
            "232/235 [============================>.] - ETA: 0s - loss: 1.4884 - accuracy: 0.4557\n",
            "Epoch 13: val_loss improved from 1.51799 to 1.50384, saving model to model1_1/13.hdf5\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 1.4878 - accuracy: 0.4561 - val_loss: 1.5038 - val_accuracy: 0.4508\n",
            "Epoch 14/50\n",
            "218/235 [==========================>...] - ETA: 0s - loss: 1.4741 - accuracy: 0.4597\n",
            "Epoch 14: val_loss improved from 1.50384 to 1.49269, saving model to model1_1/14.hdf5\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 1.4745 - accuracy: 0.4593 - val_loss: 1.4927 - val_accuracy: 0.4490\n",
            "Epoch 15/50\n",
            "229/235 [============================>.] - ETA: 0s - loss: 1.4637 - accuracy: 0.4619\n",
            "Epoch 15: val_loss improved from 1.49269 to 1.48378, saving model to model1_1/15.hdf5\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 1.4636 - accuracy: 0.4620 - val_loss: 1.4838 - val_accuracy: 0.4559\n",
            "Epoch 16/50\n",
            "227/235 [===========================>..] - ETA: 0s - loss: 1.4554 - accuracy: 0.4639\n",
            "Epoch 16: val_loss improved from 1.48378 to 1.47642, saving model to model1_1/16.hdf5\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 1.4546 - accuracy: 0.4644 - val_loss: 1.4764 - val_accuracy: 0.4556\n",
            "Epoch 17/50\n",
            "231/235 [============================>.] - ETA: 0s - loss: 1.4471 - accuracy: 0.4646\n",
            "Epoch 17: val_loss improved from 1.47642 to 1.47002, saving model to model1_1/17.hdf5\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 1.4472 - accuracy: 0.4645 - val_loss: 1.4700 - val_accuracy: 0.4610\n",
            "Epoch 18/50\n",
            "218/235 [==========================>...] - ETA: 0s - loss: 1.4422 - accuracy: 0.4677\n",
            "Epoch 18: val_loss improved from 1.47002 to 1.46491, saving model to model1_1/18.hdf5\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 1.4413 - accuracy: 0.4680 - val_loss: 1.4649 - val_accuracy: 0.4595\n",
            "Epoch 19/50\n",
            "226/235 [===========================>..] - ETA: 0s - loss: 1.4368 - accuracy: 0.4689\n",
            "Epoch 19: val_loss improved from 1.46491 to 1.46017, saving model to model1_1/19.hdf5\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.4359 - accuracy: 0.4687 - val_loss: 1.4602 - val_accuracy: 0.4613\n",
            "Epoch 20/50\n",
            "227/235 [===========================>..] - ETA: 0s - loss: 1.4316 - accuracy: 0.4694\n",
            "Epoch 20: val_loss improved from 1.46017 to 1.45634, saving model to model1_1/20.hdf5\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.4315 - accuracy: 0.4695 - val_loss: 1.4563 - val_accuracy: 0.4638\n",
            "Epoch 21/50\n",
            "222/235 [===========================>..] - ETA: 0s - loss: 1.4290 - accuracy: 0.4706\n",
            "Epoch 21: val_loss improved from 1.45634 to 1.45279, saving model to model1_1/21.hdf5\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.4275 - accuracy: 0.4710 - val_loss: 1.4528 - val_accuracy: 0.4667\n",
            "Epoch 22/50\n",
            "232/235 [============================>.] - ETA: 0s - loss: 1.4237 - accuracy: 0.4727\n",
            "Epoch 22: val_loss improved from 1.45279 to 1.45036, saving model to model1_1/22.hdf5\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 1.4242 - accuracy: 0.4726 - val_loss: 1.4504 - val_accuracy: 0.4632\n",
            "Epoch 23/50\n",
            "230/235 [============================>.] - ETA: 0s - loss: 1.4215 - accuracy: 0.4724\n",
            "Epoch 23: val_loss improved from 1.45036 to 1.44706, saving model to model1_1/23.hdf5\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 1.4210 - accuracy: 0.4725 - val_loss: 1.4471 - val_accuracy: 0.4697\n",
            "Epoch 24/50\n",
            "227/235 [===========================>..] - ETA: 0s - loss: 1.4188 - accuracy: 0.4723\n",
            "Epoch 24: val_loss improved from 1.44706 to 1.44470, saving model to model1_1/24.hdf5\n",
            "235/235 [==============================] - 2s 7ms/step - loss: 1.4183 - accuracy: 0.4729 - val_loss: 1.4447 - val_accuracy: 0.4713\n",
            "Epoch 25/50\n",
            "221/235 [===========================>..] - ETA: 0s - loss: 1.4160 - accuracy: 0.4748\n",
            "Epoch 25: val_loss improved from 1.44470 to 1.44232, saving model to model1_1/25.hdf5\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.4159 - accuracy: 0.4744 - val_loss: 1.4423 - val_accuracy: 0.4686\n",
            "Epoch 26/50\n",
            "221/235 [===========================>..] - ETA: 0s - loss: 1.4134 - accuracy: 0.4744\n",
            "Epoch 26: val_loss improved from 1.44232 to 1.44052, saving model to model1_1/26.hdf5\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 1.4135 - accuracy: 0.4742 - val_loss: 1.4405 - val_accuracy: 0.4681\n",
            "Epoch 27/50\n",
            "227/235 [===========================>..] - ETA: 0s - loss: 1.4106 - accuracy: 0.4751\n",
            "Epoch 27: val_loss improved from 1.44052 to 1.43876, saving model to model1_1/27.hdf5\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 1.4112 - accuracy: 0.4751 - val_loss: 1.4388 - val_accuracy: 0.4712\n",
            "Epoch 28/50\n",
            "227/235 [===========================>..] - ETA: 0s - loss: 1.4095 - accuracy: 0.4754\n",
            "Epoch 28: val_loss improved from 1.43876 to 1.43627, saving model to model1_1/28.hdf5\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 1.4092 - accuracy: 0.4758 - val_loss: 1.4363 - val_accuracy: 0.4701\n",
            "Epoch 29/50\n",
            "227/235 [===========================>..] - ETA: 0s - loss: 1.4066 - accuracy: 0.4761\n",
            "Epoch 29: val_loss improved from 1.43627 to 1.43445, saving model to model1_1/29.hdf5\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 1.4074 - accuracy: 0.4764 - val_loss: 1.4345 - val_accuracy: 0.4726\n",
            "Epoch 30/50\n",
            "226/235 [===========================>..] - ETA: 0s - loss: 1.4051 - accuracy: 0.4772\n",
            "Epoch 30: val_loss improved from 1.43445 to 1.43299, saving model to model1_1/30.hdf5\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 1.4054 - accuracy: 0.4764 - val_loss: 1.4330 - val_accuracy: 0.4718\n",
            "Epoch 31/50\n",
            "220/235 [===========================>..] - ETA: 0s - loss: 1.4056 - accuracy: 0.4763\n",
            "Epoch 31: val_loss improved from 1.43299 to 1.43118, saving model to model1_1/31.hdf5\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 1.4039 - accuracy: 0.4773 - val_loss: 1.4312 - val_accuracy: 0.4721\n",
            "Epoch 32/50\n",
            "229/235 [============================>.] - ETA: 0s - loss: 1.4029 - accuracy: 0.4778\n",
            "Epoch 32: val_loss improved from 1.43118 to 1.42962, saving model to model1_1/32.hdf5\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.4020 - accuracy: 0.4777 - val_loss: 1.4296 - val_accuracy: 0.4719\n",
            "Epoch 33/50\n",
            "231/235 [============================>.] - ETA: 0s - loss: 1.4000 - accuracy: 0.4767\n",
            "Epoch 33: val_loss improved from 1.42962 to 1.42818, saving model to model1_1/33.hdf5\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 1.4007 - accuracy: 0.4766 - val_loss: 1.4282 - val_accuracy: 0.4721\n",
            "Epoch 34/50\n",
            "231/235 [============================>.] - ETA: 0s - loss: 1.3992 - accuracy: 0.4787\n",
            "Epoch 34: val_loss improved from 1.42818 to 1.42650, saving model to model1_1/34.hdf5\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.3992 - accuracy: 0.4787 - val_loss: 1.4265 - val_accuracy: 0.4724\n",
            "Epoch 35/50\n",
            "235/235 [==============================] - ETA: 0s - loss: 1.3976 - accuracy: 0.4782\n",
            "Epoch 35: val_loss improved from 1.42650 to 1.42459, saving model to model1_1/35.hdf5\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 1.3976 - accuracy: 0.4782 - val_loss: 1.4246 - val_accuracy: 0.4737\n",
            "Epoch 36/50\n",
            "231/235 [============================>.] - ETA: 0s - loss: 1.3962 - accuracy: 0.4792\n",
            "Epoch 36: val_loss improved from 1.42459 to 1.42374, saving model to model1_1/36.hdf5\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 1.3962 - accuracy: 0.4790 - val_loss: 1.4237 - val_accuracy: 0.4764\n",
            "Epoch 37/50\n",
            "214/235 [==========================>...] - ETA: 0s - loss: 1.3960 - accuracy: 0.4777\n",
            "Epoch 37: val_loss improved from 1.42374 to 1.42232, saving model to model1_1/37.hdf5\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 1.3948 - accuracy: 0.4787 - val_loss: 1.4223 - val_accuracy: 0.4760\n",
            "Epoch 38/50\n",
            "221/235 [===========================>..] - ETA: 0s - loss: 1.3929 - accuracy: 0.4802\n",
            "Epoch 38: val_loss improved from 1.42232 to 1.42097, saving model to model1_1/38.hdf5\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 1.3935 - accuracy: 0.4796 - val_loss: 1.4210 - val_accuracy: 0.4768\n",
            "Epoch 39/50\n",
            "218/235 [==========================>...] - ETA: 0s - loss: 1.3920 - accuracy: 0.4799\n",
            "Epoch 39: val_loss improved from 1.42097 to 1.42020, saving model to model1_1/39.hdf5\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 1.3924 - accuracy: 0.4800 - val_loss: 1.4202 - val_accuracy: 0.4740\n",
            "Epoch 40/50\n",
            "232/235 [============================>.] - ETA: 0s - loss: 1.3912 - accuracy: 0.4799\n",
            "Epoch 40: val_loss improved from 1.42020 to 1.41846, saving model to model1_1/40.hdf5\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 1.3910 - accuracy: 0.4800 - val_loss: 1.4185 - val_accuracy: 0.4762\n",
            "Epoch 41/50\n",
            "227/235 [===========================>..] - ETA: 0s - loss: 1.3906 - accuracy: 0.4794\n",
            "Epoch 41: val_loss improved from 1.41846 to 1.41704, saving model to model1_1/41.hdf5\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 1.3899 - accuracy: 0.4800 - val_loss: 1.4170 - val_accuracy: 0.4785\n",
            "Epoch 42/50\n",
            "231/235 [============================>.] - ETA: 0s - loss: 1.3888 - accuracy: 0.4812\n",
            "Epoch 42: val_loss improved from 1.41704 to 1.41663, saving model to model1_1/42.hdf5\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 1.3888 - accuracy: 0.4814 - val_loss: 1.4166 - val_accuracy: 0.4771\n",
            "Epoch 43/50\n",
            "235/235 [==============================] - ETA: 0s - loss: 1.3879 - accuracy: 0.4813\n",
            "Epoch 43: val_loss improved from 1.41663 to 1.41532, saving model to model1_1/43.hdf5\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 1.3879 - accuracy: 0.4813 - val_loss: 1.4153 - val_accuracy: 0.4749\n",
            "Epoch 44/50\n",
            "231/235 [============================>.] - ETA: 0s - loss: 1.3872 - accuracy: 0.4818\n",
            "Epoch 44: val_loss improved from 1.41532 to 1.41395, saving model to model1_1/44.hdf5\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 1.3868 - accuracy: 0.4818 - val_loss: 1.4140 - val_accuracy: 0.4777\n",
            "Epoch 45/50\n",
            "222/235 [===========================>..] - ETA: 0s - loss: 1.3863 - accuracy: 0.4816\n",
            "Epoch 45: val_loss improved from 1.41395 to 1.41318, saving model to model1_1/45.hdf5\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 1.3857 - accuracy: 0.4818 - val_loss: 1.4132 - val_accuracy: 0.4784\n",
            "Epoch 46/50\n",
            "224/235 [===========================>..] - ETA: 0s - loss: 1.3845 - accuracy: 0.4824\n",
            "Epoch 46: val_loss improved from 1.41318 to 1.41210, saving model to model1_1/46.hdf5\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 1.3849 - accuracy: 0.4821 - val_loss: 1.4121 - val_accuracy: 0.4799\n",
            "Epoch 47/50\n",
            "224/235 [===========================>..] - ETA: 0s - loss: 1.3817 - accuracy: 0.4834\n",
            "Epoch 47: val_loss improved from 1.41210 to 1.41132, saving model to model1_1/47.hdf5\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 1.3838 - accuracy: 0.4822 - val_loss: 1.4113 - val_accuracy: 0.4791\n",
            "Epoch 48/50\n",
            "226/235 [===========================>..] - ETA: 0s - loss: 1.3831 - accuracy: 0.4832\n",
            "Epoch 48: val_loss improved from 1.41132 to 1.41098, saving model to model1_1/48.hdf5\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 1.3828 - accuracy: 0.4829 - val_loss: 1.4110 - val_accuracy: 0.4786\n",
            "Epoch 49/50\n",
            "234/235 [============================>.] - ETA: 0s - loss: 1.3820 - accuracy: 0.4822\n",
            "Epoch 49: val_loss improved from 1.41098 to 1.40938, saving model to model1_1/49.hdf5\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.3821 - accuracy: 0.4824 - val_loss: 1.4094 - val_accuracy: 0.4805\n",
            "Epoch 50/50\n",
            "223/235 [===========================>..] - ETA: 0s - loss: 1.3810 - accuracy: 0.4829\n",
            "Epoch 50: val_loss improved from 1.40938 to 1.40934, saving model to model1_1/50.hdf5\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.3812 - accuracy: 0.4828 - val_loss: 1.4093 - val_accuracy: 0.4798\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x799e0b60c250>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%reload_ext tensorboard"
      ],
      "metadata": {
        "id": "lox8oOYZT4r0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir ./logs1_1/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "iOpoojJDNPPY",
        "outputId": "4345d58e-19aa-4d12-aa7d-373d049cd9b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "ERROR: Failed to launch TensorBoard (exited with 1).\n",
              "Contents of stderr:\n",
              "2023-10-31 05:32:46.716475: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
              "2023-10-31 05:32:46.716549: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
              "2023-10-31 05:32:46.716578: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
              "2023-10-31 05:32:48.265577: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
              "\n",
              "NOTE: Using experimental fast data loading logic. To disable, pass\n",
              "    \"--load_fast=false\" and report issues on GitHub. More details:\n",
              "    https://github.com/tensorflow/tensorboard/issues/4784\n",
              "\n",
              "Address already in use\n",
              "Port 6006 is in use by another program. Either identify and stop that program, or start the server with a different port."
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " ### 4.2 Activation function: Sigmoid; Hidden neurons: [32, 16]"
      ],
      "metadata": {
        "id": "oajq2nV4-FpW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "input_layer = Input(shape=(1024, ))\n",
        "dense_layer_1 = Dense(32, activation='sigmoid')(input_layer)\n",
        "dense_layer_2 = Dense(16, activation='sigmoid')(dense_layer_1)\n",
        "output_layer = Dense(10, activation='softmax',\n",
        "                     kernel_initializer='glorot_normal')(dense_layer_2)\n",
        "\n",
        "model = Model(inputs=input_layer, outputs=output_layer)\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jmpfuK75-Jao",
        "outputId": "7c398e00-58c9-4908-d7c7-de0ffb8539ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 1024)]            0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 32)                32800     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 16)                528       \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 10)                170       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 33498 (130.85 KB)\n",
            "Trainable params: 33498 (130.85 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir model1_2\n",
        "model_path = \"model1_2/\""
      ],
      "metadata": {
        "id": "2xfLrUPL-NyD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5df379ea-1f58-4c37-deac-1b494c2d91a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘model1_2’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=adam, loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "uNXuuMy0-QbT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf ./logs1_2/fit\n",
        "tf.keras.backend.clear_session()\n"
      ],
      "metadata": {
        "id": "4U8Wf6K2-Sgc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "log_dir = \"logs1_2/fit/\" + datetime.now().strftime(\"%Y%m%d - %H%M%S\")"
      ],
      "metadata": {
        "id": "yN5zqJN--Uqr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.utils.plot_model(model, to_file=model_path +\n",
        "                          'model.png', show_shapes=True)\n",
        "\n",
        "tbCallBack = TensorBoard(log_dir=log_dir, write_graph=True,\n",
        "                         write_grads=True, write_images=True)\n",
        "\n",
        "allCs = [tbCallBack, earlystop]\n",
        "\n",
        "model.fit(x_train_tf, y_train, epochs=50,\n",
        "          validation_data=validation_data, batch_size=256, callbacks=allCs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 668
        },
        "id": "hl5lVoyk-ZJb",
        "outputId": "da327e24-6d95-470a-bb51-2f04590a71f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`write_grads` will be ignored in TensorFlow 2.0 for the `TensorBoard` Callback.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-471747de9336>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mallCs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtbCallBack\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearlystop\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m model.fit(x_train_tf, y_train, epochs=50,\n\u001b[0m\u001b[1;32m     10\u001b[0m           validation_data=validation_data, batch_size=256, callbacks=allCs)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1377, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1360, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1349, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1126, in train_step\n        y_pred = self(x, training=True)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"model\" is incompatible with the layer: expected shape=(None, 1024), found shape=(None, 32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir logs1_2"
      ],
      "metadata": {
        "id": "UxVwVZsY-mkC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}